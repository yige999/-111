# AutoSaaS Radar Backend

Python åç«¯æ¨¡å—ï¼Œè´Ÿè´£æ•°æ®æŠ“å–ã€AIåˆ†æå’ŒAPIæœåŠ¡ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥å¿…è¦çš„APIå¯†é’¥
```

### 3. å¯åŠ¨æœåŠ¡

```bash
python run.py
```

æˆ–ä½¿ç”¨uvicornï¼š

```bash
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

### 4. è®¿é—®APIæ–‡æ¡£

å¯åŠ¨åè®¿é—® http://localhost:8000/docs æŸ¥çœ‹äº¤äº’å¼APIæ–‡æ¡£ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
backend/
â”œâ”€â”€ app.py                 # FastAPIåº”ç”¨å…¥å£
â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†
â”œâ”€â”€ models.py              # æ•°æ®æ¨¡å‹
â”œâ”€â”€ run.py                 # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ requirements.txt       # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ .env.example          # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ scrapers/             # æ•°æ®æŠ“å–æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rss_scraper.py    # RSSæŠ“å–å™¨
â”‚   â”œâ”€â”€ reddit_scraper.py # RedditæŠ“å–å™¨
â”‚   â””â”€â”€ hackernews_scraper.py # HNæŠ“å–å™¨
â”œâ”€â”€ analyzers/            # AIåˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ gpt_analyzer.py   # GPTåˆ†æå™¨
â”œâ”€â”€ database/             # æ•°æ®åº“æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ supabase_client.py # Supabaseå®¢æˆ·ç«¯
â”œâ”€â”€ utils/                # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py         # æ—¥å¿—å·¥å…·
â”‚   â””â”€â”€ exceptions.py     # å¼‚å¸¸å®šä¹‰
â””â”€â”€ tests/                # æµ‹è¯•æ¨¡å—
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_scrapers.py  # æŠ“å–å™¨æµ‹è¯•
    â”œâ”€â”€ test_analyzers.py # åˆ†æå™¨æµ‹è¯•
    â””â”€â”€ test_database.py  # æ•°æ®åº“æµ‹è¯•
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

| å˜é‡å | è¯´æ˜ | å¿…éœ€ |
|--------|------|------|
| `OPENAI_API_KEY` | OpenAI APIå¯†é’¥ | âœ… |
| `OPENAI_MODEL` | OpenAIæ¨¡å‹åç§° | âŒ |
| `SUPABASE_URL` | Supabaseé¡¹ç›®URL | âœ… |
| `SUPABASE_KEY` | Supabase APIå¯†é’¥ | âœ… |
| `RSS_FEEDS` | RSSæºåˆ—è¡¨ | âŒ |
| `REDDIT_CLIENT_ID` | Redditå®¢æˆ·ç«¯ID | âŒ |
| `REDDIT_CLIENT_SECRET` | Redditå®¢æˆ·ç«¯å¯†é’¥ | âŒ |

### æ•°æ®æºé…ç½®

ç³»ç»Ÿæ”¯æŒä»¥ä¸‹æ•°æ®æºï¼š

1. **RSS Feeds**: ProductHunt, Futurepediaç­‰
2. **Reddit**: r/SaaS, r/SideProjectç­‰
3. **Hacker News**: æœ€æ–°Show HNå¸–å­

## ğŸ§ª è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/test_scrapers.py

# è¿è¡Œå¸¦è¦†ç›–ç‡çš„æµ‹è¯•
pytest --cov=. tests/

# è¿è¡Œå¼‚æ­¥æµ‹è¯•
pytest -m asyncio
```

## ğŸ“¡ APIæ¥å£

### æ ¸å¿ƒæ¥å£

- `GET /api/tools/latest` - è·å–æœ€æ–°å·¥å…·
- `GET /api/tools/category/{category}` - æŒ‰åˆ†ç±»è·å–å·¥å…·
- `GET /api/tools/trending` - è·å–è¶‹åŠ¿å·¥å…·
- `GET /api/tools/date/{date}` - æŒ‰æ—¥æœŸè·å–å·¥å…·
- `POST /api/tools/refresh` - æ‰‹åŠ¨åˆ·æ–°æ•°æ®
- `GET /api/categories` - è·å–åˆ†ç±»åˆ—è¡¨
- `GET /api/stats` - è·å–ç»Ÿè®¡ä¿¡æ¯

### ç³»ç»Ÿæ¥å£

- `GET /health` - å¥åº·æ£€æŸ¥
- `GET /docs` - APIæ–‡æ¡£
- `GET /` - æ ¹è·¯å¾„ä¿¡æ¯

## ğŸ”„ å·¥ä½œæµç¨‹

1. **æ•°æ®æŠ“å–**: å®šæ—¶æŠ“å–å„å¤§å¹³å°AIå·¥å…·ä¿¡æ¯
2. **AIåˆ†æ**: ä½¿ç”¨GPT-4oåˆ†æå·¥å…·ï¼Œæå–ç—›ç‚¹å’ŒSaaSç‚¹å­
3. **æ•°æ®å­˜å‚¨**: å°†åˆ†æç»“æœå­˜å‚¨åˆ°Supabaseæ•°æ®åº“
4. **APIæœåŠ¡**: æä¾›RESTful APIä¾›å‰ç«¯è°ƒç”¨

## ğŸ“Š æ•°æ®æ ¼å¼

### åŸå§‹å·¥å…·æ•°æ®

```json
{
  "tool_name": "AI Resume Builder",
  "description": "Build perfect resumes with AI",
  "votes": 150,
  "link": "https://example.com",
  "date": "2024-01-15T10:00:00Z",
  "category": ""
}
```

### åˆ†æåæ•°æ®

```json
{
  "tool_name": "AI Resume Builder",
  "category": "Productivity",
  "trend_signal": "Rising",
  "pain_point": "ATSç³»ç»Ÿä¼˜åŒ–å›°éš¾",
  "micro_saas_ideas": ["ç®€å†å®šåˆ¶å·¥å…·", "ATSè¯„åˆ†æ£€æŸ¥å™¨"]
}
```

## ğŸ” ç›‘æ§å’Œæ—¥å¿—

- æ—¥å¿—æ–‡ä»¶: `logs/autosaas_YYYYMMDD.log`
- æ—¥å¿—çº§åˆ«: DEBUG, INFO, WARNING, ERROR
- æ”¯æŒå½©è‰²æ§åˆ¶å°è¾“å‡º
- è‡ªåŠ¨å¼‚å¸¸æ•è·å’Œè®°å½•

## ğŸ›  å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„æ•°æ®æº

1. åœ¨ `scrapers/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æŠ“å–å™¨
2. å®ç° `fetch_*` æ–¹æ³•
3. è¿”å› `RawTool` å¯¹è±¡åˆ—è¡¨
4. åœ¨ `app.py` ä¸­é›†æˆæ–°çš„æŠ“å–å™¨

### æ·»åŠ æ–°çš„åˆ†æå™¨

1. åœ¨ `analyzers/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„åˆ†æå™¨
2. å®ç° `analyze_tools` æ–¹æ³•
3. è¿”å› `AnalyzedTool` å¯¹è±¡åˆ—è¡¨
4. åœ¨é…ç½®ä¸­å¯ç”¨æ–°çš„åˆ†æå™¨

### æ•°æ®åº“æ“ä½œ

ä½¿ç”¨ `SupabaseDB` ç±»è¿›è¡Œæ•°æ®åº“æ“ä½œï¼š

```python
from database import db

# è·å–æœ€æ–°å·¥å…·
tools = await db.get_latest_tools(limit=50)

# æ’å…¥å·¥å…·
success = await db.insert_tools(analyzed_tools)
```

## ğŸš¨ é”™è¯¯å¤„ç†

ç³»ç»ŸåŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼š

- `ScrapingError`: æ•°æ®æŠ“å–é”™è¯¯
- `AnalysisError`: AIåˆ†æé”™è¯¯
- `DatabaseError`: æ•°æ®åº“æ“ä½œé”™è¯¯
- `APIError`: APIè°ƒç”¨é”™è¯¯

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

- å¼‚æ­¥å¹¶å‘æŠ“å–
- æ•°æ®åº“è¿æ¥æ± 
- æ‰¹é‡æ•°æ®æ’å…¥
- æ™ºèƒ½å»é‡æœºåˆ¶
- GPT APIè°ƒç”¨ä¼˜åŒ–

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. ç¼–å†™æµ‹è¯•
4. æäº¤PR
5. ç­‰å¾…Review

## ğŸ“„ è®¸å¯è¯

MIT License