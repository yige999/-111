"""
æ•°æ®åº“æ¨¡å—æµ‹è¯•
"""
import asyncio
import json
from datetime import datetime, timedelta
import random
from typing import List, Dict, Any

from .data_validator import data_validator
from .database_manager import db_manager
from .batch_optimizer import batch_optimizer

def generate_test_data(count: int = 100) -> List[Dict[str, Any]]:
    """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
    categories = ["Video", "Text", "Productivity", "Marketing", "Education", "Audio", "Other"]
    trends = ["Rising", "Stable", "Declining"]

    test_tools = []
    for i in range(count):
        tool = {
            "tool_name": f"æµ‹è¯•å·¥å…· {i+1}",
            "description": f"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å·¥å…·çš„æè¿°ï¼Œç”¨äºéªŒè¯æ•°æ®åº“åŠŸèƒ½ã€‚å·¥å…·ç¼–å·ï¼š{i+1}",
            "category": random.choice(categories),
            "votes": random.randint(0, 1000),
            "link": f"https://example.com/tool{i+1}",
            "trend_signal": random.choice(trends),
            "pain_point": f"ç”¨æˆ·åœ¨ä½¿ç”¨{i+1}ç±»å·¥å…·æ—¶é‡åˆ°çš„ç—›ç‚¹æè¿°",
            "micro_saas_ideas": [
                f"åŸºäº{i+1}çš„å¾®SaaSç‚¹å­1",
                f"åŸºäº{i+1}çš„å¾®SaaSç‚¹å­2"
            ],
            "date": (datetime.now() - timedelta(days=random.randint(0, 7))).isoformat()
        }
        test_tools.append(tool)

    return test_tools

async def test_data_validation():
    """æµ‹è¯•æ•°æ®éªŒè¯"""
    print("ğŸ” æµ‹è¯•æ•°æ®éªŒè¯åŠŸèƒ½...")

    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_data = generate_test_data(10)

    # æ·»åŠ ä¸€äº›æ— æ•ˆæ•°æ®
    invalid_data = [
        {"tool_name": "", "description": "æ— æ•ˆå·¥å…·"},
        {"tool_name": "Valid Tool", "votes": -1},
        {"tool_name": "Test", "link": "invalid-url"},
        {"description": "Missing name"}  # ç¼ºå°‘å¿…è¦å­—æ®µ
    ]

    all_data = test_data + invalid_data

    # æ‰§è¡ŒéªŒè¯
    results = await data_validator.validate_batch(all_data)

    # ç»Ÿè®¡ç»“æœ
    summary = data_validator.get_validation_summary(results)
    print(f"âœ… æ•°æ®éªŒè¯å®Œæˆ:")
    print(f"   æ€»æ•°: {summary['total']}")
    print(f"   æœ‰æ•ˆ: {summary['valid']}")
    print(f"   æ— æ•ˆ: {summary['invalid']}")
    print(f"   æœ‰æ•ˆç‡: {summary['valid_rate']}%")
    print(f"   è­¦å‘Šæ•°: {summary['total_warnings']}")

    return [r.cleaned_data for r in results if r.is_valid and r.cleaned_data]

async def test_batch_insertion(valid_data: List[Dict[str, Any]]):
    """æµ‹è¯•æ‰¹é‡æ’å…¥"""
    print(f"\nğŸš€ æµ‹è¯•æ‰¹é‡æ’å…¥åŠŸèƒ½... ({len(valid_data)} é¡¹)")

    # æ€§èƒ½åŸºå‡†æµ‹è¯•
    if len(valid_data) >= 20:
        test_sample = valid_data[:20]  # ä½¿ç”¨å‰20é¡¹è¿›è¡Œæµ‹è¯•
        benchmark_result = await batch_optimizer.benchmark_performance(test_sample)

        print("âš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"   æœ€ä½³æ‰¹æ¬¡å¤§å°: {benchmark_result['best_batch_size']}")
        print(f"   æœ€ä½³æ€§èƒ½: {benchmark_result['best_performance']} é¡¹/ç§’")

        # ä½¿ç”¨æœ€ä½³æ‰¹æ¬¡å¤§å°
        batch_optimizer.batch_size = benchmark_result['best_batch_size']

    # æ‰§è¡Œæ‰¹é‡æ’å…¥
    progress_updates = []

    async def progress_callback(progress, stats, current, total):
        update = f"è¿›åº¦: {progress:.1f}% ({current}/{total}) - æˆåŠŸ: {stats.get('success', 0)}, å¤±è´¥: {stats.get('failed', 0)}"
        progress_updates.append(update)
        print(f"   {update}")

    # æ‰§è¡Œæ™ºèƒ½æ‰¹é‡æ’å…¥
    if valid_data:
        result = await batch_optimizer.smart_batch_insert(
            valid_data,
            auto_chunk_size=True
        )

        print(f"âœ… æ‰¹é‡æ’å…¥å®Œæˆ:")
        print(f"   æ€»æ•°: {result['total']}")
        print(f"   æˆåŠŸ: {result['success']}")
        print(f"   å¤±è´¥: {result['failed']}")
        print(f"   é‡å¤: {result['duplicates']}")
        print(f"   è€—æ—¶: {result['time']}ç§’")
        print(f"   é€Ÿåº¦: {result.get('items_per_second', 0)} é¡¹/ç§’")

        return result
    else:
        print("âš ï¸  æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯æ’å…¥")
        return None

async def test_database_operations():
    """æµ‹è¯•æ•°æ®åº“æ“ä½œ"""
    print("\nğŸ—„ï¸  æµ‹è¯•æ•°æ®åº“æ“ä½œåŠŸèƒ½...")

    try:
        # æµ‹è¯•è·å–ä»Šæ—¥Topå·¥å…·
        today_tools = await db_manager.get_today_top_tools(5)
        print(f"âœ… ä»Šæ—¥Topå·¥å…·: {len(today_tools)} é¡¹")

        # æµ‹è¯•è·å–è¶‹åŠ¿å·¥å…·
        trending_tools = await db_manager.get_trending_tools_by_category(days=7, limit=10)
        print(f"âœ… è¶‹åŠ¿å·¥å…·: {len(trending_tools)} é¡¹")

        # æµ‹è¯•æŒ‰åˆ†ç±»è·å–å·¥å…·
        if trending_tools:
            sample_category = trending_tools[0].get('category', 'Other')
            category_tools = await db_manager.db.get_tools_by_category(sample_category, 5)
            print(f"âœ… åˆ†ç±»å·¥å…· ({sample_category}): {len(category_tools)} é¡¹")

        # æµ‹è¯•æœç´¢åŠŸèƒ½
        search_results = await db_manager.search_tools("æµ‹è¯•", 10)
        print(f"âœ… æœç´¢ç»“æœ: {len(search_results)} é¡¹")

        # æµ‹è¯•è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = await db_manager.db.get_stats()
        print(f"âœ… ç»Ÿè®¡ä¿¡æ¯: æ€»å·¥å…· {stats.get('total_tools', 0)}, ä»Šæ—¥æ–°å¢ {stats.get('today_tools', 0)}")

        # æµ‹è¯•åˆ†ç±»æ±‡æ€»
        category_summary = await db_manager.get_category_summary(7)
        print(f"âœ… åˆ†ç±»æ±‡æ€»: {len(category_summary)} ä¸ªåˆ†ç±»")

        # æµ‹è¯•æ¯æ—¥ç»Ÿè®¡
        daily_stats = await db_manager.get_daily_stats(3)
        print(f"âœ… æ¯æ—¥ç»Ÿè®¡: {len(daily_stats)} å¤©çš„æ•°æ®")

        return True

    except Exception as e:
        print(f"âŒ æ•°æ®åº“æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_data_export():
    """æµ‹è¯•æ•°æ®å¯¼å‡º"""
    print("\nğŸ“¤ æµ‹è¯•æ•°æ®å¯¼å‡ºåŠŸèƒ½...")

    try:
        # å¯¼å‡ºJSONæ ¼å¼
        json_export = await db_manager.export_tools_data("json", 7)
        if json_export:
            print(f"âœ… JSONå¯¼å‡ºæˆåŠŸ: {len(json_export)} å­—ç¬¦")

        # å¯¼å‡ºCSVæ ¼å¼
        csv_export = await db_manager.export_tools_data("csv", 7)
        if csv_export:
            print(f"âœ… CSVå¯¼å‡ºæˆåŠŸ: {len(csv_export)} å­—ç¬¦")

        return True

    except Exception as e:
        print(f"âŒ æ•°æ®å¯¼å‡ºæµ‹è¯•å¤±è´¥: {e}")
        return False

async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹æ•°æ®åº“æ¨¡å—å®Œæ•´æµ‹è¯•\n")

    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if not db_manager.db.test_connection():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return False

    print("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")

    # æµ‹è¯•1: æ•°æ®éªŒè¯
    valid_data = await test_data_validation()

    # æµ‹è¯•2: æ‰¹é‡æ’å…¥
    insert_result = await test_batch_insertion(valid_data)

    # æµ‹è¯•3: æ•°æ®åº“æ“ä½œ
    db_ops_result = await test_database_operations()

    # æµ‹è¯•4: æ•°æ®å¯¼å‡º
    export_result = await test_data_export()

    # æ€»ç»“
    print("\n" + "="*50)
    print("ğŸ¯ æµ‹è¯•æ€»ç»“:")
    print(f"   æ•°æ®éªŒè¯: âœ…")
    print(f"   æ‰¹é‡æ’å…¥: {'âœ…' if insert_result else 'âŒ'}")
    print(f"   æ•°æ®åº“æ“ä½œ: {'âœ…' if db_ops_result else 'âŒ'}")
    print(f"   æ•°æ®å¯¼å‡º: {'âœ…' if export_result else 'âŒ'}")

    success = db_ops_result and export_result
    print(f"\nğŸš€ æ•°æ®åº“æ¨¡å—æµ‹è¯•: {'å…¨éƒ¨é€šè¿‡' if success else 'éƒ¨åˆ†å¤±è´¥'}")

    if insert_result:
        print(f"ğŸ“Š æ’å…¥ç»Ÿè®¡: æˆåŠŸ {insert_result['success']}, å¤±è´¥ {insert_result['failed']}, é‡å¤ {insert_result['duplicates']}")

    return success

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(run_all_tests())