import re
import logging
from typing import List, Optional, Set
from datetime import datetime, timezone

from ..models import RawTool

logger = logging.getLogger(__name__)


class DataCleaner:
    """æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–å·¥å…·"""

    def __init__(self):
        self.duplicate_links: Set[str] = set()
        self.processed_count = 0

    def clean_tools_list(self, tools: List[RawTool]) -> List[RawTool]:
        """æ¸…æ´—å·¥å…·åˆ—è¡¨"""
        cleaned_tools = []

        for tool in tools:
            cleaned_tool = self.clean_single_tool(tool)
            if cleaned_tool and self._is_valid_tool(cleaned_tool):
                cleaned_tools.append(cleaned_tool)

        logger.info(f"æ¸…æ´—å®Œæˆï¼šä» {len(tools)} ä¸ªå·¥å…·æ¸…ç†ä¸º {len(cleaned_tools)} ä¸ªæœ‰æ•ˆå·¥å…·")
        return cleaned_tools

    def clean_single_tool(self, tool: RawTool) -> Optional[RawTool]:
        """æ¸…æ´—å•ä¸ªå·¥å…·æ•°æ®"""
        try:
            # æ¸…æ´—å·¥å…·åç§°
            cleaned_name = self._clean_tool_name(tool.tool_name)

            # æ¸…æ´—æè¿°
            cleaned_description = self._clean_description(tool.description)

            # æ ‡å‡†åŒ–åˆ†ç±»
            cleaned_category = self._standardize_category(tool.category, cleaned_name, cleaned_description)

            # éªŒè¯å¹¶æ ‡å‡†åŒ–URL
            cleaned_link = self._validate_and_normalize_url(tool.link)

            # éªŒè¯æŠ•ç¥¨æ•°
            cleaned_votes = self._validate_votes(tool.votes)

            # ç¡®ä¿æ—¥æœŸæœ‰æ•ˆ
            cleaned_date = self._validate_date(tool.date)

            if not cleaned_name or not cleaned_link:
                return None

            return RawTool(
                tool_name=cleaned_name,
                description=cleaned_description,
                votes=cleaned_votes,
                link=cleaned_link,
                date=cleaned_date,
                category=cleaned_category
            )

        except Exception as e:
            logger.error(f"æ¸…æ´—å·¥å…·æ•°æ®å¤±è´¥: {e}")
            return None

    def _clean_tool_name(self, name: str) -> str:
        """æ¸…æ´—å·¥å…·åç§°"""
        if not name:
            return ""

        # ç§»é™¤å¸¸è§çš„åƒåœ¾å‰ç¼€å’Œåç¼€
        patterns_to_remove = [
            r'^\s*[-*_]\s*',
            r'\s*[-*_]\s*$',
            r'^\[.*?\]\s*',
            r'\s*\[.*?\]\s*$',
            r'^\s*\d+\.\s*',
            r'^\s*\d+\)\s*',
            r'ğŸš€\s*|âœ¨\s*|ğŸ¯\s*|â­\s*',  # ç§»é™¤emojiå‰ç¼€
        ]

        cleaned = name
        for pattern in patterns_to_remove:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)

        # é™åˆ¶é•¿åº¦
        cleaned = cleaned.strip()[:100]

        # ç§»é™¤å¤šä½™ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned)

        return cleaned

    def _clean_description(self, description: str) -> str:
        """æ¸…æ´—æè¿°æ–‡æœ¬"""
        if not description:
            return ""

        # ç§»é™¤HTMLæ ‡ç­¾
        cleaned = re.sub(r'<[^>]+>', '', description)

        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œå¤šä½™ç©ºç™½
        cleaned = re.sub(r'[^\w\s\-\.\,\!\?\:\;]', ' ', cleaned)
        cleaned = re.sub(r'\s+', ' ', cleaned)

        # ç§»é™¤é‡å¤çš„å¥å­æˆ–çŸ­è¯­
        sentences = cleaned.split('. ')
        unique_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence and not any(self._similarity_check(sentence, existing) for existing in unique_sentences):
                unique_sentences.append(sentence)

        # é‡æ–°ç»„åˆå¹¶é™åˆ¶é•¿åº¦
        cleaned = '. '.join(unique_sentences[:3])  # æœ€å¤šä¿ç•™3å¥è¯
        cleaned = cleaned.strip()[:500]  # é™åˆ¶æ€»é•¿åº¦

        return cleaned

    def _standardize_category(self, original_category: str, tool_name: str, description: str) -> str:
        """æ ‡å‡†åŒ–åˆ†ç±»"""
        if original_category:
            # æ ‡å‡†åŒ–ç°æœ‰åˆ†ç±»
            category_mapping = {
                'video editing': 'Video',
                'video generation': 'Video',
                'text generation': 'Text',
                'content creation': 'Text',
                'productivity tools': 'Productivity',
                'task management': 'Productivity',
                'marketing tools': 'Marketing',
                'social media': 'Marketing',
                'educational': 'Education',
                'learning': 'Education',
                'audio processing': 'Audio',
                'music generation': 'Audio',
                'image generation': 'Image',
                'photo editing': 'Image',
                'code generation': 'Code',
                'programming': 'Code'
            }

            standardized = category_mapping.get(original_category.lower(), original_category)
            if standardized in ['Video', 'Text', 'Productivity', 'Marketing', 'Education', 'Audio', 'Image', 'Code']:
                return standardized

        # å¦‚æœæ²¡æœ‰åˆ†ç±»æˆ–åˆ†ç±»æ— æ•ˆï¼ŒåŸºäºåç§°å’Œæè¿°æ¨æ–­
        return self._infer_category(tool_name, description)

    def _infer_category(self, tool_name: str, description: str) -> str:
        """åŸºäºå·¥å…·åç§°å’Œæè¿°æ¨æ–­åˆ†ç±»"""
        text = (tool_name + ' ' + description).lower()

        category_keywords = {
            'Video': ['video', 'movie', 'animation', 'film', 'video generation', 'video editing'],
            'Text': ['text', 'writing', 'content', 'copywriting', 'article', 'blog', 'text generation'],
            'Productivity': ['productivity', 'task', 'workflow', 'automation', 'efficiency', 'management'],
            'Marketing': ['marketing', 'seo', 'social media', 'advertising', 'email', 'promotion'],
            'Education': ['education', 'learning', 'tutoring', 'course', 'teaching', 'training'],
            'Audio': ['audio', 'music', 'voice', 'sound', 'podcast', 'speech', 'music generation'],
            'Image': ['image', 'photo', 'picture', 'graphic', 'design', 'image generation'],
            'Code': ['code', 'programming', 'development', 'coding', 'software', 'api']
        }

        for category, keywords in category_keywords.items():
            if any(keyword in text for keyword in keywords):
                return category

        return ""

    def _validate_and_normalize_url(self, url: str) -> str:
        """éªŒè¯å¹¶æ ‡å‡†åŒ–URL"""
        if not url:
            return ""

        # ç§»é™¤URLå‚æ•°
        url = re.sub(r'[?&](utm_[^&]*|ref=[^&]*|source=[^&]*)', '', url)

        # ç¡®ä¿æœ‰åè®®
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url

        # éªŒè¯URLæ ¼å¼
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            if parsed.netloc and parsed.scheme in ['http', 'https']:
                return url
        except:
            pass

        return ""

    def _validate_votes(self, votes: int) -> int:
        """éªŒè¯æŠ•ç¥¨æ•°"""
        if not isinstance(votes, int) or votes < 0:
            return 0
        # é™åˆ¶æœ€å¤§æŠ•ç¥¨æ•°ï¼Œé˜²æ­¢å¼‚å¸¸æ•°æ®
        return min(votes, 10000)

    def _validate_date(self, date: datetime) -> datetime:
        """éªŒè¯æ—¥æœŸ"""
        if not isinstance(date, datetime):
            return datetime.now(timezone.utc)

        # ç¡®ä¿æ—¥æœŸåœ¨åˆç†èŒƒå›´å†…ï¼ˆä¸èƒ½å¤ªæ—©æˆ–å¤ªæ™šï¼‰
        now = datetime.now(timezone.utc)
        one_year_ago = now.replace(year=now.year - 1)

        if date > now:
            return now
        elif date < one_year_ago:
            return one_year_ago

        return date

    def _is_valid_tool(self, tool: RawTool) -> bool:
        """éªŒè¯å·¥å…·æ˜¯å¦æœ‰æ•ˆ"""
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if not tool.tool_name or not tool.link:
            return False

        # æ£€æŸ¥æ˜¯å¦å·²é‡å¤ï¼ˆåŸºäºé“¾æ¥ï¼‰
        if tool.link in self.duplicate_links:
            return False

        # æ£€æŸ¥å·¥å…·åç§°é•¿åº¦
        if len(tool.tool_name) < 3 or len(tool.tool_name) > 100:
            return False

        # æ·»åŠ åˆ°å·²å¤„ç†é›†åˆ
        self.duplicate_links.add(tool.link)
        self.processed_count += 1

        return True

    def _similarity_check(self, text1: str, text2: str, threshold: float = 0.8) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        if not text1 or not text2:
            return False

        # ç®€å•çš„ç›¸ä¼¼åº¦æ£€æŸ¥ï¼šå…±åŒè¯æ±‡æ¯”ä¾‹
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())

        if not words1 or not words2:
            return False

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        similarity = len(intersection) / len(union) if union else 0
        return similarity >= threshold

    def get_statistics(self) -> dict:
        """è·å–æ¸…æ´—ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'processed_count': self.processed_count,
            'duplicate_count': len(self.duplicate_links)
        }


def clean_and_validate_tools(tools: List[RawTool]) -> List[RawTool]:
    """ä¾¿æ·å‡½æ•°ï¼šæ¸…æ´—å’ŒéªŒè¯å·¥å…·åˆ—è¡¨"""
    cleaner = DataCleaner()
    return cleaner.clean_tools_list(tools)